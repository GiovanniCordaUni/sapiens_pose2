# Configurazione per l'elaborazione dei video con rilevamento pose Sapiens
# Utilizza il modello Sapiens con checkpoint COCO 17 nativo

# paths
paths:
  # Root directories
  input_root: "data/input"
  output_root: "data/output"
  sapiens_host: "sapiens_host" # Directory principale per i modelli Sapiens
  
  # Subdirectories (relative alla root)
  frames_dir: "frames"
  videos_dir: "videos"
  keypoints_dir: "keypoints_jsonl"
  overlay_dir: "overlay_videos"

# Models
models:
  yolo:
    weights: "weights/yolo/yolov8n.pt"
    confidence: 0.30
    imgsz: 640
    person_class_id: 0  # COCO class ID for person
    
  sapiens:
    # COCO 17 native checkpoint - output diretto 17 keypoints, nessun mapping richiesto
    # checpoint: "pose/checkpoints/sapiens_0.6b/sapiens_0.6b_coco_best_coco_AP_812_torchscript.pt2"
    # checkpoint: "pose/checkpoints/sapiens_1b/sapiens_1b_coco_best_coco_AP_821_torchscript.pt2"
    checkpoint: "pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796_torchscript.pt2"
    input_width: 768
    input_height: 1024

# detection
detection:
  # padding per bounding box (come frazione della dimensione della box)
  box_padding: 0.20
  # IoU bias per NMS di YOLO
  iou_bias: 0.7

# processing
processing:
  # processa ogni N-esimo frame
  frame_stride: 1
  # Device: "cuda", "cpu", or "auto" (auto-detect)
  device: "auto"

# visualizzazione
visualization:
  # Keypoint confidence threshold per il disegno
  keypoint_threshold: 0.35
  # Circle radius for keypoints
  keypoint_radius: 5
  # Line thickness for skeleton
  skeleton_thickness: 2
  # Colors (BGR format)
  keypoint_color: [0, 255, 0]  # green
  skeleton_color: [0, 255, 0]  # green
  bbox_color: [255, 0, 0]      # blue
